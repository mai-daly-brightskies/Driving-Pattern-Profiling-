{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/preprocessed/preprocessed_train.csv\")\n",
    "test_data = pd.read_csv(\"../data/preprocessed/preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriver_d_path1 = train_data[(train_data['Class']==\"D\") & (train_data['PathOrder']==1) ]\n",
    "deriver_d_path2 = train_data[(train_data['Class']==\"D\") & (train_data['PathOrder']==2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\1283051211.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deriver_d_path1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\1283051211.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deriver_d_path2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "deriver_d_path1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "deriver_d_path2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_deriver_data_path1 = deriver_d_path1.values\n",
    "one_deriver_data_path2 = deriver_d_path2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.data = data.float()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx:idx+self.sequence_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 60\n",
    "dataset_path1 = TimeSeriesDataset(one_deriver_data_path1, sequence_length)\n",
    "dataset_path2 = TimeSeriesDataset(one_deriver_data_path2, sequence_length)\n",
    "concatenated_data = ConcatDataset([dataset_path1, dataset_path2])\n",
    "dataloader = DataLoader(concatenated_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexTimeSeriesAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, sequence_lengt):\n",
    "        super(ComplexTimeSeriesAutoencoder, self).__init__()\n",
    "        \n",
    "        # Define the CNN Encoder\n",
    "        self.cnn_encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Define the LSTM Encoder\n",
    "        self.lstm_encoder = nn.LSTM(input_size=64, hidden_size=latent_dim, batch_first=True)\n",
    "        \n",
    "        # Define the LSTM Decoder\n",
    "        self.lstm_decoder = nn.LSTM(input_size=latent_dim, hidden_size=64, batch_first=True)\n",
    "        \n",
    "        # Define the CNN Decoder\n",
    "        self.cnn_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=input_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the CNN Encoder\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, input_dim, sequence_length) for CNN\n",
    "        x = self.cnn_encoder(x)\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, sequence_length, num_channels) for LSTM\n",
    "        \n",
    "        # Pass through the LSTM Encoder\n",
    "        x, _ = self.lstm_encoder(x)\n",
    "        \n",
    "        # Pass through the LSTM Decoder\n",
    "        x, _ = self.lstm_decoder(x)\n",
    "        \n",
    "        # Pass through the CNN Decoder\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch_size, num_channels, sequence_length) for CNN\n",
    "        x = self.cnn_decoder(x)\n",
    "        x = x.permute(0, 2, 1)  # Change shape back to (batch_size, sequence_length, input_dim)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1726, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_deriver_data_path1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = one_deriver_data_path1.shape[1]\n",
    "latent_dim = 20\n",
    "model = ComplexTimeSeriesAutoencoder(input_dim, latent_dim, sequence_length).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 5.3163\n",
      "Epoch [2/20], Loss: 7.7159\n",
      "Epoch [3/20], Loss: 6.0024\n",
      "Epoch [4/20], Loss: 7.2494\n",
      "Epoch [5/20], Loss: 6.4511\n",
      "Epoch [6/20], Loss: 6.7225\n",
      "Epoch [7/20], Loss: 4.8788\n",
      "Epoch [8/20], Loss: 5.5105\n",
      "Epoch [9/20], Loss: 5.5099\n",
      "Epoch [10/20], Loss: 4.9683\n",
      "Epoch [11/20], Loss: 5.9810\n",
      "Epoch [12/20], Loss: 5.1820\n",
      "Epoch [13/20], Loss: 6.6218\n",
      "Epoch [14/20], Loss: 5.0998\n",
      "Epoch [15/20], Loss: 6.5156\n",
      "Epoch [16/20], Loss: 7.2608\n",
      "Epoch [17/20], Loss: 4.8451\n",
      "Epoch [18/20], Loss: 5.7954\n",
      "Epoch [19/20], Loss: 7.2420\n",
      "Epoch [20/20], Loss: 5.9700\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        batch = batch.float().to(device)\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\824658257.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\824658257.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_data_one_deriver_2 = test_data[(test_data['Class']==\"D\") & (test_data['PathOrder']==2) ]\n",
    "test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "test_data_one_deriver_1 = test_data[(test_data['Class']==\"D\") & (test_data['PathOrder']==1) ]\n",
    "test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path2 = TimeSeriesDataset(test_data_one_deriver_2.values, sequence_length)\n",
    "test_dataset_path1 = TimeSeriesDataset(test_data_one_deriver_1.values, sequence_length)\n",
    "concatenated_data = ConcatDataset([test_dataset_path1, test_dataset_path2])\n",
    "test_dataloader = DataLoader(concatenated_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error threshold: 46.8258\n"
     ]
    }
   ],
   "source": [
    "def calculate_reconstruction_error(model, dataloader):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.float().to(device)\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "            errors.append(loss.item())\n",
    "    return errors\n",
    "\n",
    "validation_errors = calculate_reconstruction_error(model, test_dataloader)\n",
    "threshold = np.mean(validation_errors) + 3 * np.std(validation_errors)\n",
    "print(f'Reconstruction error threshold: {threshold:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.float().to(device)\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        # print(loss)\n",
    "        if loss.item() > threshold:\n",
    "            anomalies.append(True)\n",
    "        else:\n",
    "            anomalies.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute on another driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\2157133497.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\2157133497.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "driver_cls = \"A\"\n",
    "test_data_one_deriver_1 = train_data[(train_data['Class']==driver_cls) & (train_data['PathOrder']==1) ]\n",
    "test_data_one_deriver_2 = train_data[(train_data['Class']==driver_cls) & (train_data['PathOrder']==2) ]\n",
    "test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "test_dataset_path2 = TimeSeriesDataset(test_data_one_deriver_2.values, sequence_length)\n",
    "test_dataset_path1 = TimeSeriesDataset(test_data_one_deriver_1.values, sequence_length)\n",
    "concatenated_data = ConcatDataset([test_dataset_path1, test_dataset_path2])\n",
    "test_dataloader = DataLoader(concatenated_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.float().to(device)\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        # print(loss)\n",
    "        if loss.item() > threshold:\n",
    "            anomalies.append(True)\n",
    "        else:\n",
    "            anomalies.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9302067946824224\n"
     ]
    }
   ],
   "source": [
    "true_count = 0\n",
    "for res in anomalies:\n",
    "    if res:\n",
    "        true_count += 1\n",
    "print(f\"acc: {true_count/len(anomalies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_per_class():\n",
    "    deriver_classes = train_data['Class'].unique()\n",
    "    for deriver_cls in deriver_classes:\n",
    "        test_data_one_deriver_1 = train_data[(train_data['Class']==deriver_cls) & (train_data['PathOrder']==1) ]\n",
    "        test_data_one_deriver_2 = train_data[(train_data['Class']==deriver_cls) & (train_data['PathOrder']==2) ]\n",
    "        test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "        test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
    "        test_dataset_path2 = TimeSeriesDataset(test_data_one_deriver_2.values, sequence_length)\n",
    "        test_dataset_path1 = TimeSeriesDataset(test_data_one_deriver_1.values, sequence_length)\n",
    "        concatenated_data = ConcatDataset([test_dataset_path1, test_dataset_path2])\n",
    "        test_dataloader = DataLoader(concatenated_data, batch_size=1, shuffle=True)\n",
    "        anomalies_cnt = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                batch = batch.float().to(device)\n",
    "                outputs = model(batch)\n",
    "                loss = criterion(outputs, batch)\n",
    "                if loss.item() > 11:\n",
    "                    anomalies_cnt += 1\n",
    "        print(f\"class {deriver_cls}  acc: {anomalies_cnt/(len(test_data_one_deriver_1)+len(test_data_one_deriver_2))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class A  acc: 0.9575671852899575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class D  acc: 0.0023860021208907743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class B  acc: 0.4149377593360996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class C  acc: 0.8813216453135536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class I  acc: 0.8969477183439105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class J  acc: 0.9698037242073477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class H  acc: 0.9237187127532777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class G  acc: 0.8048200950441277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class F  acc: 0.7366903283052352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_1.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n",
      "C:\\Users\\mdaly\\AppData\\Local\\Temp\\ipykernel_25112\\706439255.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_one_deriver_2.drop(columns=['Time(s)', 'PathOrder', 'Class'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class E  acc: 0.9681359532660648\n"
     ]
    }
   ],
   "source": [
    "evalute_per_class()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
